
<!doctype html>
<html lang="ja" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://W-Uchida.github.io/class/%E5%8C%BB%E7%94%A8%E7%94%BB%E5%83%8F%E5%87%A6%E7%90%86%E5%B7%A5%E5%AD%A6/12_ai/">
      
      
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.7">
    
    
      
        <title>13.AI・機械学習による医用画像解析 - 講義資料ポータル</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.8608ea7d.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../css/custom.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
   <link href="../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }
    .gscrollbar-fixer { padding-right: 15px; }
    .gdesc-inner { font-size: 0.75rem; }
    body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
    body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
    body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}</style> <script src="../../assets/javascripts/glightbox.min.js"></script></head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="lime" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#13ai" class="md-skip">
          コンテンツにスキップ
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="ヘッダー">
    <a href="../.." title="講義資料ポータル" class="md-header__button md-logo" aria-label="講義資料ポータル" data-md-component="logo">
      
  <img src="../../img/00-logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            講義資料ポータル
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              13.AI・機械学習による医用画像解析
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="検索" placeholder="検索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="検索">
        
        <button type="reset" class="md-search__icon md-icon" title="クリア" aria-label="クリア" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            検索を初期化
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/W-Uchida/class" title="リポジトリへ" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="ナビゲーション" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="講義資料ポータル" class="md-nav__button md-logo" aria-label="講義資料ポータル" data-md-component="logo">
      
  <img src="../../img/00-logo.png" alt="logo">

    </a>
    講義資料ポータル
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/W-Uchida/class" title="リポジトリへ" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    画像解析・画像AI特論
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            画像解析・画像AI特論
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../%E7%94%BB%E5%83%8F%E8%A7%A3%E6%9E%90%E3%83%BB%E7%94%BB%E5%83%8FAI%E7%89%B9%E8%AB%96/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    概要
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../%E7%94%BB%E5%83%8F%E8%A7%A3%E6%9E%90%E3%83%BB%E7%94%BB%E5%83%8FAI%E7%89%B9%E8%AB%96/lecture01/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第1章
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../%E7%94%BB%E5%83%8F%E8%A7%A3%E6%9E%90%E3%83%BB%E7%94%BB%E5%83%8FAI%E7%89%B9%E8%AB%96/lecture02/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第2章
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../%E7%94%BB%E5%83%8F%E8%A7%A3%E6%9E%90%E3%83%BB%E7%94%BB%E5%83%8FAI%E7%89%B9%E8%AB%96/lecture03/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第3章
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目次">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目次
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1" class="md-nav__link">
    <span class="md-ellipsis">
      1. 導入・概要
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1. 導入・概要">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11-ai" class="md-nav__link">
    <span class="md-ellipsis">
      1.1 従来手法からAI手法への発展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2" class="md-nav__link">
    <span class="md-ellipsis">
      2. 機械学習・深層学習の基礎
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. 機械学習・深層学習の基礎">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21" class="md-nav__link">
    <span class="md-ellipsis">
      2.1 機械学習の基本概念
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22-deep-learning" class="md-nav__link">
    <span class="md-ellipsis">
      2.2 深層学習（Deep Learning）入門
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#23-ai" class="md-nav__link">
    <span class="md-ellipsis">
      2.3 医用画像AIの特徴
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-ai" class="md-nav__link">
    <span class="md-ellipsis">
      3. 医用画像AIの主要手法
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. 医用画像AIの主要手法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-classification" class="md-nav__link">
    <span class="md-ellipsis">
      3.1 分類（Classification）
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-object-detection" class="md-nav__link">
    <span class="md-ellipsis">
      3.2 物体検出（Object Detection）
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33" class="md-nav__link">
    <span class="md-ellipsis">
      3.3 セグメンテーション（深層学習版）
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#34-registration" class="md-nav__link">
    <span class="md-ellipsis">
      3.4 Registration（深層学習版）
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#35" class="md-nav__link">
    <span class="md-ellipsis">
      3.5 生成モデル
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4" class="md-nav__link">
    <span class="md-ellipsis">
      4. 倫理・法的課題と今後の展望
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4. 倫理・法的課題と今後の展望">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#41-ai" class="md-nav__link">
    <span class="md-ellipsis">
      4.1 医療AI特有の倫理的課題
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#42" class="md-nav__link">
    <span class="md-ellipsis">
      4.2 薬事承認と標準化
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-google-colab" class="md-nav__link">
    <span class="md-ellipsis">
      5. Google Colab実習
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6" class="md-nav__link">
    <span class="md-ellipsis">
      6. まとめ・総合討論
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6. まとめ・総合討論">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#61-3" class="md-nav__link">
    <span class="md-ellipsis">
      6.1 3回の講義を通じた学習の統合
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="13ai">13.AI・機械学習による医用画像解析</h1>
<h2 id="1">1. 導入・概要</h2>
<p>本日は、AI・機械学習技術が医用画像解析の分野でどのように活用され、医療現場にどのような変化をもたらすのかについて学びます。</p>
<h3 id="11-ai">1.1 従来手法からAI手法への発展</h3>
<p>これまでの講義で学んだ画像処理技術は、AI、特に深層学習（Deep Learning）の登場によって大きな変革期を迎えています。</p>
<ul>
<li>
<p><strong>従来の画像処理との違い</strong></p>
<ul>
<li>
<p><strong>ルールベース → 学習ベース</strong>:</p>
<ul>
<li><strong>従来手法（ルールベース）</strong>: 人間が「輝度値が100以上200以下は骨」「特定のエッジを検出したら臓器の輪郭」といったように、<strong>明確なルール（アルゴリズム）を設計</strong>していました。この方法は、条件が限定された特定のタスクでは有効ですが、画像のばらつき（ノイズ、撮影条件の違い、個体差）に弱く、複雑なパターン認識は困難でした。</li>
<li><strong>AI手法（学習ベース）</strong>: 大量のデータ（画像と正解ラベルのペア）をAIモデルに与え、<strong>AI自らが画像の中から特徴量やルールを自動で学習</strong>します。これにより、人間が明示的にルール化できないような複雑なパターンも認識可能になり、より高い精度と汎用性を実現します。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>これまでの講義との関連</strong></p>
<ul>
<li><strong>セグメンテーション</strong>: 前回の講義で学んだ閾値処理や領域成長法などの従来手法は、パラメータ調整が煩雑でした。深層学習ベースのセグメンテーション（例：U-Net）は、医師が描いたお手本（教師データ）から学習し、<strong>臓器や病変の輪郭を高速かつ高精度に自動抽出</strong>します。</li>
<li><strong>Registration</strong>: 従来の位置合わせ（Registration）は、相互情報量などの指標を最大化するために反復計算を行い、時間がかかることが課題でした。学習ベースの手法は、多くの画像ペアの変形パターンを事前に学習しておくことで、<strong>新しい画像が入力された際に瞬時に位置合わせを完了</strong>させることが可能になります。</li>
</ul>
</li>
</ul>
<hr />
<h2 id="2">2. 機械学習・深層学習の基礎</h2>
<p>AIを理解するために、その中核技術である機械学習と深層学習の基本を学びましょう。</p>
<h3 id="21">2.1 機械学習の基本概念</h3>
<p>機械学習は、データから学習し、予測や判断を行うためのアルゴリズムの総称です。その多くは統計学的なモデルに基づいています。</p>
<ul>
<li>
<p><strong>教師あり学習 vs 教師なし学習</strong></p>
<ul>
<li><strong>教師あり学習 (Supervised Learning)</strong>: <strong>問題（入力データ）と正解（教師ラベル）のペア</strong>を使って学習する方法。医用画像解析で最も広く使われます。<ul>
<li><strong>分類 (Classification)</strong>: データを predefined なカテゴリに分ける問題。<ul>
<li>例: 病変の画像から「良性」か「悪性」かを判定する。</li>
<li><strong>代表的な統計学的手法</strong>:<ul>
<li><strong>ロジスティック回帰</strong>: 特徴量の重み付き和をシグモイド関数に入力し、事象の発生確率（例: 悪性である確率）を0から1の間で予測する。</li>
<li><strong>サポートベクターマシン (SVM)</strong>: 異なるクラスのデータ点間の距離（マージン）が最大となるような境界線を引くことで、未知のデータを分類する。</li>
</ul>
</li>
</ul>
</li>
<li><strong>回帰 (Regression)</strong>: 連続的な数値を予測する問題。<ul>
<li>例: 腫瘍の画像からその「体積(mm³)」や「直径(mm)」を予測する。</li>
<li><strong>代表的な統計学的手法</strong>:<ul>
<li><strong>線形回帰</strong>: データ点全体の誤差が最小になるような直線（または平面・超平面）を求めることで、目的の数値を予測する。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><strong>教師なし学習 (Unsupervised Learning)</strong>: <strong>正解ラベルがないデータ</strong>から、データに潜む構造やパターンを見つけ出す方法。<ul>
<li><strong>クラスタリング (Clustering)</strong>: データを似たもの同士のグループ（クラスタ）に分ける。<ul>
<li>例: 脳の組織画像を、特徴に基づいて「灰白質」「白質」「脳脊髄液」の3つのグループに自動で分類する。</li>
</ul>
</li>
<li><strong>代表的な統計学的手法</strong>:<ul>
<li><strong>k-means法</strong>: 指定したクラスタ数k個の中心点をランダムに配置し、「各データ点を最も近い中心点に割り当てる→中心点をクラスタの重心に移動させる」という処理を繰り返すことで、データをグループ分けする。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>学習・検証・テストデータの分割</strong></p>
<ul>
<li>AIモデルの性能を正しく評価するため、手元のデータを通常3つに分割します。</li>
<li><strong>学習データ (Training Data)</strong>: モデルの学習（パラメータの最適化）に用いる最も量の多いデータ。教科書に相当します。</li>
<li><strong>検証データ (Validation Data)</strong>: 学習中にモデルの性能を評価し、過学習の監視やハイパーパラメータ（学習率など）の調整に用いるデータ。模擬試験に相当します。</li>
<li><strong>テストデータ (Test Data)</strong>: 学習が完了したモデルの最終的な性能（汎化性能）を評価するための、全く未知のデータ。本番の試験に相当します。</li>
</ul>
</li>
<li>
<p><strong>過学習（Overfitting）とその対策</strong></p>
<ul>
<li><strong>過学習</strong>とは、モデルが学習データに過剰に適合してしまい、未知のデータ（検証・テストデータ）に対して性能が低下してしまう現象です。学習データ（教科書）の問題は100点が取れるのに、模擬試験や本番の試験では点数が取れない状態です。</li>
<li><strong>原因</strong>: 学習データが少ない、モデルが複雑すぎる、など。</li>
<li><strong>対策</strong>:<ul>
<li><strong>データ拡張 (Data Augmentation)</strong>: 画像を回転、反転、拡大・縮小させるなどして、学習データを水増しする。</li>
<li><strong>正則化 (Regularization)</strong>: モデルの複雑さにペナルティを課し、過学習を抑制する。（例: Dropout, Weight Decay）</li>
<li><strong>早期終了 (Early Stopping)</strong>: 検証データの性能が改善しなくなった時点で学習を打ち切る。</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr />
<h3 id="22-deep-learning">2.2 深層学習（Deep Learning）入門</h3>
<p>深層学習は機械学習の一分野であり、その基礎には<strong>パーセプトロン</strong>という単純なモデルがあります。</p>
<ul>
<li><strong>パーセプトロン：ニューラルネットワークの原点</strong><ul>
<li><strong>理論</strong>: パーセプトロンは、複数の入力信号（x₁, x₂, ...）を受け取り、それぞれに固有の<strong>重み (w₁, w₂, ...)</strong> を掛け合わせます。その総和が設定された<strong>閾値 (θ)</strong> を超えた場合に「1」（発火）を、超えなければ「0」（発火しない）を出力する、というアルゴリズムです。これは、生物のニューロン（神経細胞）が複数の他のニューロンから信号を受け取って発火する仕組みを、数理的にモデル化したものです。</li>
<li>数式で表すと </li>
</ul>
</li>
</ul>
<div class="arithmatex">\[y = 1  \quad if Σwᵢxᵢ &gt; θ\]</div>
<p>そうでなければ <span class="arithmatex">\(y = 0\)</span> となります。</p>
<figure>
  <a class="glightbox" href="../img/13-01.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img src="../img/13-01.png" alt="パーセプトロン" width="400" height="auto"></a>
  <figcaption>パーセプトロン</figcaption>
</figure>

<ul>
<li><strong>単純パーセプトロンの限界と多層パーセプトロン</strong>（MLP）<ul>
<li>しかし、この単純なパーセプトロンには<strong>「線形分離可能な問題しか解けない」</strong>という重大な限界があります。簡単に言うと、一本の直線で分けられるような単純な問題しか扱えません。</li>
</ul>
</li>
</ul>
<figure>
  <a class="glightbox" href="../img/13-02.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img src="../img/13-02.png" alt="単純パーセプトロンの限界" width="800" height="auto"></a>
  <figcaption>単純パーセプトロンの限界</figcaption>
</figure>

<ul>
<li>
<p>この限界を克服するために考案されたのが<strong>多層パーセプトロン（Multilayer Perceptron, MLP）</strong>です。主な改良点は2つです。</p>
</li>
<li>
<p><strong>アイデア１：層を重ねる（多層化）</strong></p>
<ul>
<li>「パーセプトロン1個でダメなら、たくさん並べてチームで解決しよう！」という発想です。</li>
<li>入口（入力層）と出口（出力層）の間に、<strong>隠れ層（Hidden Layer）</strong>と呼ばれる中間層を設けました。パーセプトロンを複数階層に重ねることで、一本の直線ではなく、<strong>より複雑で非線形な境界線</strong>を引けるようになり、XORのような問題も解けるようになりました。これが<strong>多層パーセプトロン（Multilayer Perceptron, MLP）</strong>です。</li>
</ul>
</li>
</ul>
<figure>
  <a class="glightbox" href="../img/13-05.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img src="../img/13-05.png" alt="ニューラルネットワーク" width="800" height="auto"></a>
  <figcaption>多層パーセプトロン</figcaption>
</figure>

<ol>
<li>
<p><strong>アイデア２：出力の仕方を滑らかにする（活性化関数の変更）</strong></p>
<ul>
<li>これが最も重要なブレークスルーです。</li>
<li>パーセプトロンの出力は「0か1か」の階段状の関数でした。これを<strong>ステップ関数</strong>と呼びます。これでは、モデルが予測を間違えても<strong>「どれくらい間違えたのか（どのくらいの確率か？）」</strong>が分かりません。「正解は1なのに、あなたの答えは0だ。残念！」としか言えず、重みをどう修正すれば正解に近づくのか、ヒントがないのです。</li>
<li>そこで、このスイッチを<strong>滑らかな（微分可能な）関数</strong>に変えることで、。例えば、<strong>シグモイド関数</strong>などです。</li>
</ul>
<p><strong>シグモイド関数:</strong>
   $$ \sigma(z) = \frac{1}{1 + e^{-z}} $$</p>
<ul>
<li><span class="arithmatex">\(z\)</span>: ここには、先ほどの重み付き入力の合計（<span class="arithmatex">\(\sum w_ix_i\)</span>）が入ります。</li>
<li><span class="arithmatex">\(e\)</span>: ネイピア数と呼ばれる数学の定数（約2.718）です。</li>
<li><strong>関数の働き</strong>: この関数は、どんなに大きな値や小さな値が<span class="arithmatex">\(z\)</span>に入ってきても、<strong>出力値を必ず0から1の間の「滑らかな」数値に変換</strong>してくれます。例えば、出力が「0.9」なら"ほぼ1で確信度が高い"、「0.1」なら"ほぼ0で確信度が高い"、「0.51」なら"1だと思うけど、あまり自信はない"といった、<strong>答えの確信度合い</strong>を表現できるようになりました。</li>
</ul>
</li>
</ol>
<figure>
  <a class="glightbox" href="../img/13-04.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img src="../img/13-04.png" alt="活性化関数" width="800" height="auto"></a>
  <figcaption>活性化関数</figcaption>
</figure>

<figure>
  <a class="glightbox" href="../img/13-03.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img src="../img/13-03.png" alt="多層パーセプトロン+活性化関数の導入" width="800" height="auto"></a>
  <figcaption>多層パーセプトロン+活性化関数の導入</figcaption>
</figure>

<ul>
<li>
<p><strong>「誤差逆伝播法」の登場：AIが自ら学ぶ方法の確立</strong></p>
<p>出力が滑らかな数値になったことで、<strong>「正解と予測のズレ（誤差）」</strong>を数式で測れるようになりました。</p>
<p>「学習」とは、<strong>損失関数（誤差関数）</strong>と呼ばれる「正解と予測のズレ（誤差）」を表す関数を用意して、それを最小化することをいいます。</p>
<p>例えば、<strong>損失関数</strong> <span class="arithmatex">\(L\)</span> を以下のように定義します。</p>
<p><strong>損失関数 (例:二乗誤差):</strong></p>
<div class="arithmatex">\[ L = \frac{1}{2}(y_{true} - y_{pred})^2 \]</div>
<ul>
<li><span class="arithmatex">\(y_{true}\)</span>: 実際の正解ラベル（例: 1）</li>
<li><span class="arithmatex">\(y_{pred}\)</span>: AIの予測出力（例: 0.7）</li>
<li><span class="arithmatex">\(L\)</span>: この値が<strong>AIの「間違いの大きさ」</strong>です。これを最小にすることが学習の目標です。</li>
</ul>
</li>
<li>
<p>例：猫の画像を入力したときに、猫/犬/車のどれかを分類したい問題を考える</p>
<ul>
<li>この時、正解ラベルは<span class="arithmatex">\([猫, 犬, 車] = [1,0,0]\)</span></li>
<li>AIの予測出力が<span class="arithmatex">\([猫_{pred}, 犬_{pred}, 車_{pred}] = [0.7,0.25,0.05]\)</span></li>
<li>先の関数<span class="arithmatex">\(L\)</span>を損失関数とすると、<span class="arithmatex">\(L = \frac{1}{2}(1-0.7)^2=0.045\)</span> これを小さくするように重みを調整していくのが、学習！</li>
</ul>
<p>シグモイド関数のように出力が滑らか（数学的には<strong>微分可能</strong>）になったおかげで、この間違いの大きさ <span class="arithmatex">\(L\)</span> を元にして、<strong>「この間違いを減らすには、どの重み <span class="arithmatex">\(w\)</span> を、どちらの方向に、どれだけ動かせば良いか」</strong>を計算できるようになったのです。</p>
<p>この<strong>「出力層で出た誤差を、逆向きに入力層に向かって伝えながら、各層の重み <span class="arithmatex">\(w\)</span> を少しずつ賢く調整していく」</strong>手法を<strong>誤差逆伝播法（バックプロパゲーション）</strong>と呼びます。これは、AIが<strong>「間違いから学ぶ」</strong>ための、非常に効率的な学習アルゴリズムです。</p>
</li>
<li>
<p><strong>ニューラルネットワークの基本構造</strong></p>
<p>この多層パーセプトロンのように、ニューロン（パーセプトロン）を層状に多数つないだものが<strong>ニューラルネットワーク</strong>です。そして、この隠れ層が多数（一般に2層以上）あるニューラルネットワークを用いた機械学習の手法全体が<strong>「深層学習（Deep Learning）」</strong>と呼ばれます。</p>
<ul>
<li><strong>入力層 (Input Layer)</strong>: 画像のピクセル値など、最初のデータを受け取る層。</li>
<li><strong>隠れ層 (Hidden Layer)</strong>: 入力層と出力層の間にあり、データの特徴を学習する層。この隠れ層を多数持つネットワークが「深層」学習（Deep Learning）と呼ばれます。</li>
<li><strong>出力層 (Output Layer)</strong>: 分類結果（例：「良性」の確率）など、最終的な予測結果を出力する層。</li>
<li><strong>活性化関数 (Activation Function)</strong>: パーセプトロンの「0か1か」という階段状の出力（ステップ関数）を、より滑らかで微分可能な関数（例: <strong>ReLU, Sigmoid</strong>）に置き換えたものです。これにより、ネットワークがより柔軟で複雑なパターンを学習できる<strong>非線形性</strong>がもたらされ、効率的な学習（誤差逆伝播法）が可能になります。</li>
<li><strong>損失関数 (Loss Function)</strong>: モデルの予測結果と正解ラベルとの「誤差」を計算する関数。学習の目的は、この損失関数の値を最小化することです。</li>
</ul>
</li>
<li>
<p><strong>畳み込みニューラルネットワーク（CNN）</strong></p>
<ul>
<li><strong>Convolutional Neural Network</strong>の略で、画像認識タスクで絶大な性能を発揮する深層学習モデルです。</li>
<li><strong>畳み込み層 (Convolutional Layer)</strong>: 「フィルタ（カーネル）」と呼ばれる小さな行列を画像上でスライドさせながら計算（畳み込み演算）し、<strong>局所的な特徴（エッジ、色、テクスチャなど）を抽出</strong>します。層が深くなるにつれて、より大域的で複雑な特徴（目、鼻、顔など）を学習していきます。</li>
<li><strong>プーリング層 (Pooling Layer)</strong>: 抽出した特徴マップのサイズを縮小する層。これにより、計算量を削減するとともに、対象物の<strong>位置が多少ずれても同じように認識できる</strong>頑健性（ロバスト性）を獲得します。</li>
<li><strong>なぜ画像認識に適しているか</strong>: CNNは、画像の「局所性（隣接ピクセルは関連性が高い）」と「並進不変性（猫が画像の右にいても左にいても猫と認識できる）」という性質をうまく利用した構造になっているため、画像データから効率的に特徴を学習できます。</li>
</ul>
</li>
</ul>
<figure>
  <a class="glightbox" href="../img/13-08.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img src="../img/13-08.png" alt="CNN" width="800" height="auto"></a>
  <figcaption>CNN</figcaption>
</figure>

<div style="text-align: center; margin: 20px 0;">
<a href="../html/03/03-05.html" style="display: inline-block; padding: 12px 24px; background-color: #2563eb; color: white; text-decoration: none; border-radius: 6px; font-weight: bold;">
<h4><strong>🔍【実習】 畳み込み</strong></h4>
</a>
</div>

<figure>
  <a class="glightbox" href="../img/13-07.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img src="../img/13-07.png" alt="CNN" width="800" height="auto"></a>
  <figcaption>max pooling</figcaption>
</figure>

<h3 id="23-ai">2.3 医用画像AIの特徴</h3>
<p>一般的な画像（犬や猫など）を扱うAIと、医用画像を扱うAIにはいくつかの重要な違いがあります。</p>
<ul>
<li>
<p><strong>一般画像 vs 医用画像</strong></p>
<ul>
<li><strong>次元とチャネル</strong>: 一般画像は主にRGBの3チャネルを持つ2D画像ですが、医用画像は<strong>グレースケール（1チャネル）</strong>が多く、CTやMRIのように<strong>多数のスライスを持つ3次元（Volumetric）データ</strong>が基本となります。</li>
<li><strong>解像度とデータサイズ</strong>: 医用画像は非常に高解像度かつ3次元データが多く、1症例あたりのデータサイズが巨大になる傾向があります。</li>
<li><strong>専門知識の必要性</strong>: 医用画像の解釈には高度な医学的・解剖学的知識が不可欠です。AIの性能評価や教師データの作成には、医師や放射線技師などの専門家の協力が欠かせません。</li>
</ul>
</li>
<li>
<p><strong>データの課題</strong></p>
<ul>
<li><strong>教師データ作成の困難さ</strong>: 質の高い教師データ（アノテーション）を作成するには、専門医が膨大な時間をかけて病変の輪郭を描くなどの作業が必要で、コストと時間が非常にかかります。</li>
<li><strong>個人情報保護、倫理的配慮</strong>: 医用画像は究極の個人情報です。AI開発に利用する際は、患者の同意取得はもちろん、氏名やIDなどを削除する<strong>匿名化処理</strong>が厳格に求められます。</li>
<li><strong>施設間でのデータ品質差</strong>: 撮影装置のメーカー（GE, Siemens, Philipsなど）や撮像プロトコル、再構成アルゴリズムの違いにより、施設間で画質が大きく異なる場合があります。ある施設で開発したAIが、別の施設ではうまく機能しない「汎化性能」の問題が常に課題となります。</li>
</ul>
</li>
</ul>
<hr />
<h2 id="3-ai">3. 医用画像AIの主要手法</h2>
<p>ここでは、医用画像解析で実際に使われる代表的なAIのタスクと手法を見ていきます。</p>
<h3 id="31-classification">3.1 分類（Classification）</h3>
<p>画像全体に対して一つのラベルを割り当てるタスクです。</p>
<ul>
<li>
<p><strong>画像レベル分類の例</strong>:</p>
<ul>
<li><strong>胸部X線画像</strong>: 画像全体を見て「正常」か「肺炎の疑いあり」かを分類する。</li>
<li><strong>病理組織画像</strong>: パッチ（小領域）ごとに「癌細胞あり」か「なし」かを分類する。</li>
</ul>
</li>
<li>
<p><strong>代表的なCNNアーキテクチャ</strong>:</p>
<ul>
<li><strong>ResNet (Residual Network)</strong>: 「スキップ接続」という構造で層を深くしても学習しやすくしたモデル。多くのAIの基礎となる。</li>
<li><strong>DenseNet</strong>: 各層がそれ以前のすべての層と密に接続する構造を持ち、特徴の再利用を促進します。</li>
<li><strong>EfficientNet</strong>: モデルの深さ、幅、解像度をバランス良くスケールさせることで、高い精度と効率を両立したモデル。</li>
</ul>
</li>
<li>
<p><strong>転移学習 (Transfer Learning)</strong></p>
<ul>
<li>何百万枚もの一般画像（ImageNetなど）で学習済みのモデルをベースとして、少量の医用画像データで追加学習（ファインチューニング）を行う手法。</li>
<li>ゼロから学習するよりも効率的で、少ないデータでも高い性能を達成できるため、医用画像AI開発では必須のテクニックとなっています。</li>
</ul>
</li>
</ul>
<div style="text-align: center; margin: 20px 0;">
<a href="https://www.fujifilm.com/jp/ja/healthcare/healthcare-it/diagnostic-support/cxr-aid" style="display: inline-block; padding: 1px 24px; background-color:rgb(238, 248, 179); color: black; text-decoration: none; border-radius: 6px; font-weight: bold;">
<h4><strong>🔍胸部X線病変検出（富士フイルム）</strong></h4>
</a></div>

<h3 id="32-object-detection">3.2 物体検出（Object Detection）</h3>
<p>画像の中から「どこに」「何が」あるかを、バウンディングボックス（矩形）で囲って特定するタスクです。</p>
<ul>
<li>
<p><strong>病変検出の自動化</strong>:</p>
<ul>
<li><strong>肺結節検出</strong>: 胸部CT画像から、がんの可能性がある結節の位置と大きさを自動で検出する。</li>
<li><strong>骨折検出</strong>: X線画像から骨折部位を検出する。</li>
<li><strong>ポリープ検出</strong>: 内視鏡動画からリアルタイムでポリープを検出する。</li>
</ul>
</li>
<li>
<p><strong>主要アルゴリズム</strong>:</p>
<ul>
<li><strong>YOLO (You Only Look Once)</strong>: 画像を一度見るだけで高速に物体を検出できるアルゴリズム。リアルタイム検出に向いています。</li>
<li><strong>R-CNN系 (Faster R-CNNなど)</strong>: 領域候補抽出とクラス分類を2段階で行う高精度な手法。</li>
</ul>
</li>
</ul>
<div style="text-align: center; margin: 20px 0;">
<a href="https://eirl.ai/ja/eirl-colon_polyp/" style="display: inline-block; padding: 1px 24px; background-color:rgb(238, 248, 179); color: black; text-decoration: none; border-radius: 6px; font-weight: bold;">
<h4><strong>🔍⼤腸内視鏡 ポリープ検出（エルピクセル株式会社）</strong></h4>
</a></div>

<h3 id="33">3.3 セグメンテーション（深層学習版）</h3>
<p>画像のピクセル（ボクセル）一つ一つがどのクラスに属するかを分類するタスクです。臓器や病変の精密な形状を抽出します。</p>
<ul>
<li>
<p><strong>従来手法との比較</strong>:</p>
<ul>
<li><strong>閾値処理 → U-Net</strong>: 従来手法では困難だった、境界が不明瞭な軟部組織や、複雑な形状を持つ腫瘍の輪郭も、深層学習モデル（特にU-Net）はデータから学習し、高精度に抽出できます。</li>
<li><strong>手動輪郭描画 → 自動セグメンテーション</strong>: 医師が時間をかけて行っていた輪郭描画作業（トレーシング）を、AIが数秒で完了させることが可能になり、放射線治療計画や術前シミュレーションの効率を劇的に改善します。</li>
</ul>
</li>
<li>
<p><strong>主要アーキテクチャ</strong>:</p>
<ul>
<li><strong>U-Net</strong>: 医用画像セグメンテーションのために開発された、非常に有名なモデル。エンコーダ（収縮パス）とデコーダ（拡張パス）がU字型に対称な構造を持ち、スキップ接続によって詳細な位置情報を保持できるのが特徴です。</li>
<li><strong>3D U-Net</strong>: U-Netを3次元データ（CT, MRI）に対応させたモデル。 volumetric data を直接扱えるため、スライス間の連続性を考慮した、より正確な3次元セグメンテーションが可能です。</li>
</ul>
</li>
</ul>
<div style="text-align: center; margin: 20px 0;">
<a href="https://reili.fujifilm.com/en/tag/segmentation/index.html" style="display: inline-block; padding: 1px 24px; background-color:rgb(238, 248, 179); color: black; text-decoration: none; border-radius: 6px; font-weight: bold;">
<h4><strong>🔍セグメンテーション活用例（富士フィルムメディカル）</strong></h4>
</a></div>

<h3 id="34-registration">3.4 Registration（深層学習版）</h3>
<p>異なる時点で撮影された画像や、異なるモダリティの画像（CTとMRIなど）を空間的に位置合わせするタスクです。</p>
<ul>
<li>
<p><strong>従来の反復最適化 → 学習ベース</strong>:</p>
<ul>
<li><strong>計算時間の大幅短縮</strong>: 従来法は画像ペアごとに反復計算が必要で時間がかかりましたが、学習ベースの手法（VoxelMorphなど）は、一度モデルを学習すれば、推論時はニューラルネットワークを一回通すだけで済み、<strong>数分〜数十分かかっていた処理が数秒で完了</strong>します。</li>
<li><strong>複雑な変形への対応</strong>: 呼吸や臓器の動きによる複雑な非剛体変形も、データから学習することで高精度に対応できます。</li>
</ul>
</li>
<li>
<p><strong>主要手法</strong>:</p>
<ul>
<li><strong>VoxelMorph</strong>: 教師なし学習（変形後画像の類似度を最大化）で変形場を直接推定する、代表的な深層学習Registration手法。</li>
</ul>
</li>
</ul>
<h3 id="35">3.5 生成モデル</h3>
<p>新しいデータを生成したり、データを変換したりするモデルです。</p>
<ul>
<li>
<p><strong>GAN (Generative Adversarial Networks)</strong>:</p>
<ul>
<li><strong>生成器 (Generator)</strong> と <strong>識別器 (Discriminator)</strong> という2つのネットワークを敵対的に競わせながら学習するモデル。「偽札を作る者」と「それを見破る鑑定士」に例えられます。</li>
<li><strong>応用</strong>:<ul>
<li><strong>データ拡張</strong>: 希少疾患など、データが少ない場合にリアルな医用画像を生成し、学習データを増やす。</li>
<li><strong>異常検出</strong>: 正常画像のみを学習させ、入力された画像がどれだけ「正常らしくないか」をスコア化することで、予期せぬ異常を検出する。</li>
<li><strong>モダリティ変換</strong>: CT画像からMRI画像を生成する、など。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>VAE (Variational Autoencoder)</strong>:</p>
<ul>
<li>入力データを一度低次元の潜在空間に圧縮（エンコード）し、そこから元のデータを復元（デコード）するモデル。</li>
<li><strong>応用</strong>:<ul>
<li><strong>画像復元・ノイズ除去</strong>: ノイズの多い画像からクリーンな画像を復元する。</li>
</ul>
</li>
</ul>
</li>
</ul>
<div style="text-align: center; margin: 20px 0;">
<a href="https://jp.medical.canon/products/computed-tomography/ct-aice" style="display: inline-block; padding: 1px 24px; background-color:rgb(238, 248, 179); color: black; text-decoration: none; border-radius: 6px; font-weight: bold;">
<h4><strong>🔍高画質化（キヤノンメディカルシステムズ）</strong></h4>
</a></div>

<hr />
<h2 id="4">4. 倫理・法的課題と今後の展望</h2>
<p>AIを医療に用いる上では、技術的な課題だけでなく、倫理的・法的な側面も考慮しなければなりません。</p>
<h3 id="41-ai">4.1 医療AI特有の倫理的課題</h3>
<ul>
<li>
<p><strong>説明可能性（Explainable AI, XAI）</strong>:</p>
<ul>
<li><strong>ブラックボックス問題</strong>: 深層学習モデルはなぜその結論に至ったのか、判断根拠を人間が理解するのが難しい場合があります。医師がAIの診断結果を鵜呑みにするのではなく、その根拠を理解し、最終判断を下すためには、AIの判断プロセスを可視化・説明する技術（XAI）が重要です。</li>
</ul>
</li>
<li>
<p><strong>バイアス問題</strong>:</p>
<ul>
<li>AIは学習データに含まれる偏り（バイアス）を学習してしまいます。例えば、特定の性別や人種のデータばかりで学習すると、それ以外の集団に対して性能が著しく低下する可能性があります。医療の公平性を担保するため、学習データの多様性に配慮することが不可欠です。</li>
</ul>
</li>
<li>
<p><strong>責任の所在</strong>:</p>
<ul>
<li>AIが関与した誤診が発生した場合、その責任は誰が負うのでしょうか？AIを開発したメーカーか、導入した病院か、それとも最終判断を下した医師か。明確な法的枠組みがまだ整備されておらず、今後の重要な議論のテーマです。現状では、<strong>AIはあくまで支援ツールであり、最終的な診断・治療の責任は医師にある</strong>とされています。</li>
</ul>
</li>
</ul>
<h3 id="42">4.2 薬事承認と標準化</h3>
<ul>
<li><strong>医療機器としての承認プロセス</strong>: AIを用いたソフトウェアも、診断や治療に用いられる場合は「医療機器」として扱われ、日本ではPMDA、米国ではFDAによる厳格な審査（薬事承認）を受ける必要があります。有効性と安全性を証明するための臨床性能試験が必須です。</li>
<li><strong>国際標準化動向</strong>: AI医療機器の評価方法や品質管理に関する国際的な標準規格（ISO/IECなど）の策定が進んでいます。これにより、世界中で安全かつ有効なAIが利用できる環境が整備されつつあります。</li>
</ul>
<hr />
<h2 id="5-google-colab">5. Google Colab実習</h2>
<ul>
<li><a href="https://drive.google.com/file/d/13K3AFToAi7cOYJXTNJTaUKSsBWXnlIUf/view?usp=sharing">Google colabファイル1 - MNIST</a></li>
<li><a href="https://drive.google.com/file/d/1ayGSoeIiLHz0K5SdBxlzAzjTNazRsO57/view?usp=sharing">Google colabファイル2 - CT</a></li>
</ul>
<hr />
<h2 id="6">6. まとめ・総合討論</h2>
<h3 id="61-3">6.1 3回の講義を通じた学習の統合</h3>
<p>本日の講義で、医用画像解析の技術が大きな転換点を迎えていることをご理解いただけたと思います。</p>
<ul>
<li><strong>技術の発展段階</strong>:</li>
<li><strong>従来手法（ルールベース）</strong>: 人間がアルゴリズムを設計する、職人技の世界。</li>
<li><strong>機械学習・深層学習</strong>: データからAIが自動で学習し、人間の能力を超える認識性能を実現する世界。</li>
<li><strong>臨床応用の段階</strong>:</li>
<li>これまで学んできたセグメンテーションやRegistrationといった古典的なタスクが、深層学習によって<strong>自動化・高速化・高精度化</strong>され、研究から実用化のフェーズへと移行しています。</li>
</ul>
<p>AIは、医師の診断を支援し、医療の質と効率を向上させる強力なツールです。しかし、その性能を最大限に引き出し、安全に運用するためには、AIの原理を理解し、その限界と課題を正しく認識することが不可欠です。</p>







  
    
  
  
    
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="最終更新日">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="2025年9月29日 01:24:19 UTC">2025年9月29日</span>
  </span>

    
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="作成日">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="2025年9月29日 01:24:19 UTC">2025年9月29日</span>
  </span>

    
    
    
  </aside>





                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/W-Uchida/class" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.sections", "navigation.expand", "search.highlight", "search.suggest"], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "\u30b3\u30d4\u30fc\u3057\u307e\u3057\u305f", "clipboard.copy": "\u30af\u30ea\u30c3\u30d7\u30dc\u30fc\u30c9\u3078\u30b3\u30d4\u30fc", "search.result.more.one": "\u3053\u306e\u30da\u30fc\u30b8\u5185\u306b\u3082\u30461\u4ef6\u898b\u3064\u304b\u308a\u307e\u3057\u305f", "search.result.more.other": "\u3053\u306e\u30da\u30fc\u30b8\u5185\u306b\u3042\u3068#\u4ef6\u898b\u3064\u304b\u308a\u307e\u3057\u305f", "search.result.none": "\u4f55\u3082\u898b\u3064\u304b\u308a\u307e\u305b\u3093\u3067\u3057\u305f", "search.result.one": "1\u4ef6\u898b\u3064\u304b\u308a\u307e\u3057\u305f", "search.result.other": "#\u4ef6\u898b\u3064\u304b\u308a\u307e\u3057\u305f", "search.result.placeholder": "\u691c\u7d22\u30ad\u30fc\u30ef\u30fc\u30c9\u3092\u5165\u529b\u3057\u3066\u304f\u3060\u3055\u3044", "search.result.term.missing": "\u691c\u7d22\u306b\u542b\u307e\u308c\u306a\u3044", "select.version": "\u30d0\u30fc\u30b8\u30e7\u30f3\u5207\u308a\u66ff\u3048"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.c8b220af.min.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  <script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(() => { lightbox.reload() });
</script></body>
</html>